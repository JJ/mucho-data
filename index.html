<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Mucho data</title>

		<meta name="description" content="Big data, presentación para Open E2 Arena + IEEE Developer Days">
		<meta name="author" content="JJ Merelo">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/league.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h1>Mucho Data</h1>
					<h3>Cuando los datos crecen</h3>
					<p>Por <a
			href="http://jj.github.io">JJ Merelo</a> / <a
			href="http://twitter.com/jjmerelo"><code>@jjmerelo</code></a></p>

					<aside class='notes'>En el
				programa decía que iba a hablar de
				software libre también. Pero es que,
				como leí ayer en Twitter <a
				href='http://osdelivers.blackducksoftware.com/2015/05/13/the-open-source-default/#.VVRm3BPP9es.twitter'>hoy
				en día ha crecido el software libre
					  hasta tal punto que es la
				opción por omisión</a>. En general,
				todas las herramientas que voy a
				comentar son libres; si alguna no lo
					  es, lo diré explícitamente.</aside>
				</section>

				<section
				data-background='img/viaje-datos.jpg'
				alt='autobús NY'>
				  <aside class='notes'>Mucho data es
				un viaje data, como en el
				chiste. "¿Quieres un viaje a Túnez?"
				    "¿Para qué quiero yo tanto
				pescado?"</aside>
				</section>

				<section data-background='https://johnnymackintosh.files.wordpress.com/2011/08/asimov-foundation-covers-cropped.jpg' title='Trilogía de la fundación'>
				  
				  <aside class='notes'>La <a
				href='http://en.wikipedia.org/wiki/Psychohistory_%28fictional%29'>Psicohistoria</a>
				fue propuesta por Asimov en su
				trilogía de la fundación y viene a
				decir que la historia de una masa de
				gente suficientemente grande puede ser
				    predicha, incluso con mucha antelación</aside>
				</section>

				<section data-background='http://sparkleberrysprings.com/v-web/b2/images/entertainment/asimovmule.jpg' title="El mulo">
				  <aside class='notes'>El Mulo no se podía predecir por tal psicohistoria. Y la lió pardísima, claro.</aside>
				</section>

				<section data-background='https://farm8.staticflickr.com/7133/6863172432_d9cda26a6f_k_d.jpg' title='gente con móviles'>
				  <aside class='notes'>Cuando hay
				  mucha gente, o dispositivos, usando
				  la Internet y produciendo datos es
				  cuando nos encontramos con
				  el <em>big data</em>. Y eso siempre
				  deja una huella, que podemos
				  analizar.</aside>

				</section>

				<section data-background='https://farm5.staticflickr.com/4088/4999986578_5ff5a242a7_b_d.jpg' title='muchas filas y columnas'>
				  <aside class='notes'>Técnicamente se
				  trata de trabajar con múltiples
				  filas y columnas, como en estas
				  sillas. Todo el tiempo añaden
				  sillas. Se sienta gente. ¿Cuánta
				  gente hay sentada en la 6ª fila?
				    ¿Cuánta gente hay delante
				    mío? El que sea <a href='http://en.wikipedia.org/wiki/Big_data'>big data</a> depende de
				 las filas, las columnas y del número
				  de las mismas que se añaden cada
				  cierto tiempo.  </aside>
				</section>

				<section data-background='img/uves-ancient-history.jpg'
				  title='Uves'>
				  <aside class='notes'>Se habla de 5
				  uves: velocidad, variedad,
				  veracidad,  volumen y variabilidad,
				  aparte de una C, que es
				    complejidad. Lo que ocurre es
				  que, en general, no se trata con el
				  big data directamente. Se suele
				  tratar con el resultado de procesar
				  esas técnicas de big data. Pero,
				  ¿de dónde salen esos datos?</aside>
				</section>
				
				<section data-background='img/los-de-elche.png'
				  alt='buscando'>
				  <aside class='notes'>Cada vez que
				  buscamos se está generando un dato
				  que además va geolocalizado y por
				  supuesto asignado a nuestro usuario
				  de Google. Cada vez también que
				  encendemos un móvil Android (y
				  supongo que también otros) la
				  localización se almacena y se sigue
				  almacenando si tienes activado
				  Google Now. Cada vez que se visita
				  una página en la Wikipedia también
				  se queda registardo, o una web
				  cualquiera. También hay grandes
				  cantidades de datos de origen
				  biológico, datos de tráfico, datos
				  de la administración (a veces
				  disponibles como datos abiertos),
				  metadatos de mensajes en sistemas
				  como WhatsApp... uno genera datos
				  sin saberlo por su actividad online,
				  pero también se genera en todo tipo
				  de actividades, siempre que se
				  registren. No siempre son ni
				  abiertos ni grandotes, pero pueden
				  llegar a serlo con el tiempo o si
				    los fusionamos con otros. Pero,
				  ¿de dónde sacamos los datos?</aside>

				</section>

				<section>
				  <section data-background='img/la-piara.jpg' title='Paté la Piara, más bueno que el pan. Que no he encontrado el Apis'>
				    <aside class='notes'>
				      <p>Aquí tenía que venir una
					transpa de APIs, el paté, ya sabéis,
					Apis, Papis. Era lo que iba buscando
					pero me encontré una historia que,
				  curiosamente, tiene que ver con el
				      <em>big data</em>. Buscando
				  imágenes para ilustrar esta
				  transparencia, no encontré ninguna
				  buena. Así que, no reparando en
				  esfuerzos para tener una
				  transparencia chachi, me fui al
				  Mercadona local a buscar paté Apis,
				  tomate triturado Apis o lo que
				  fuera. No lo encontré (y saqué esta
				  foto en vez de la anterior). Pero
				  buscando la razón por la que un
				  elemento tan fundamental de las
				  meriendas no estaba en Mercadona, me
				      encontré con <a
				  href='http://blogs.elconfidencial.com/espana/el-confidente/2009-02-13/el-clan-familiar-ruiz-mateos-se-moviliza-para-ir-a-comprar-apis-a-mercadona_441793/'>esta
				  noticia</a> que habla de como la
				      <em>big family</em> de Ruiz
				  Mateos trató de engañar a los
				      algoritmos <em>big data</em> de
				  Mercadona mandando a miembros de la
				  familia extensa a pedir o comprar
				  sus productos o reclamarlos en caso
				  de que no lo encontraran. Lo que
				  ocurre es que trataron de difundir
				  la campaña por correo electrónico y,
				  por equivocación, lo enviaron a la
				  propia Mercadona. Algo muy común en
				      las <em>big family</em>, que
				  siempre hay una prima que se llama
				  Mercadona o trabaja en el Mercadona
				  o que se llama Mercedes pero, por su
				  afición a los productos Hacendado,
				      le llaman Mercedona. O algo.</p>

				      <p>Los denominados
				  APIs, o interfaces de aplicación de
				  programas, permiten extraer
				  información ya procesada sobre la
				  actividad online en una serie de
				  servicios. Los APIs permiten
				  recuperar tweets en Twitter, likes
				  en Facebook, visitas en la Wikipedia
				  y una gran cantidad de cosas sobre
				  la actividad pública de la
				  gente. También se puede acceder a
				  otro tipo de APIs, recordad que el
				  big data no se refiere a la gente:
				  por
				  ejemplo <a href='http://en.wikipedia.org/wiki/List_of_financial_data_feeds'>datos
				      de acciones en bolsa</a>
				  o <a href='https://code.google.com/p/googletransitdatafeed/wiki/PublicFeeds'>datos
				      de tráfico</a>
				  o <a href='http://stats.stackexchange.com/questions/12670/data-apis-feeds-available-as-packages-in-r'>datos
				      de todo tipo, desde el tiempo
				  hasta archivos</a>. Por cierto,
				  vemos por primera vez R, el lenguaje
				  que se usa, por excelencia, para
				  trabajar con los datos. Lo veremos
					más adelante.</p>
				    </aside>

				  </section>
				  
				  <section>
				    <img src='img/UMH-vs-UA-wikipedia.png' alt='Visitas a la página de la wikipedia'>
				    <aside class='notes'><p>Por ejemplo,
				    usando un API muy simple de la
				    Wikipedia se pueden descargar las
				    visitas a las páginas día a
				    día. Aquí las visitas a la página
				    de la Universidad de Alicante y la
				      de la Miguel Hernández, por
				      ejemplo.</p>

				    <p>De hecho, la Wikipedia da
				  acceso a <a
				  href='https://wikitech.wikimedia.org/wiki/Analytics'>una
				  buena cantidad de datos de una forma
				      sencilla</a>. Viene a ser una de las
				  banderas de la nueva web: se crean
				  plataformas, no sólo sitios con
				  contenido. También es un signo de
				  transparencia: por eso se puede
				  acceder de esa forma a los datos de
				  la Wikipedia (y no tanto a los de
				      FB, por ejemplo).</p>< </aside>
				  </section>
				  
				  <section>
				    <pre><code>for (year in (2010:2014)) {
    for (month in (1:12)) {
        theURL <- "http://stats.grok.se/json/es/"
        theURL <- paste0(theURL, year) # Adapta cosas        
        theURL <- paste0(theURL, month) 
        theURL.ugr <- paste0(theURL, "/Universidad_Miguel_Hernández")
        rawData.ugr <- getURL(theURL.ugr)
        data.UMH <- fromJSON(rawData.ugr)
        df.UMH <- data.frame(Date=names(data.UMH$daily_views),Views=data.UMH$daily_views)
        df.UMH <-  df.UMH[df.UMH$Views > 0,]
        df.UMH$Date <- as.Date(df.UMH$Date)
        alldata.UMH <- rbind( alldata.UMH, df.UMH )
    }
}
alldata.UA <- alldata.UA[order(alldata.UA$Date),]</code></pre>

				    <aside class='notes'>Es sólo parte
        del programa, que se puede descargar <a
				      href='datos/univs.R'>de
				    aquí</a>; también se puede
				    consultar la historia de R. En
				    cualquier caso, si no entendéis
				    del tema no tenéis que
				    preocuparos: está escrito en un
				    lenguaje llamado R, que es un
				    lenguaje que os vais a encontrar
				    una y otra vez cuando se habla de
				    ciencia de datos y de big
				    data. La idea es que los APIs o
				      interfaces de programación
				    <em>publican</em> los datos en un
				    formato estándar, que se pueden
				    usar desde cualquier lenguaje de
				    programación, en particular este
				    R</aside>
				  </section>
				</section>

				<section>
				  
				  <section
				    data-background='https://farm8.staticflickr.com/7467/15897351745_ccc1232f4e_h_d.jpg'
title='Rascando/scraping'>
				    <aside class='notes'>Scraping es
				      extraer datos de dónde estén
				      publicados sin, en principio,
				      intención de que se descarguen. 
				    </aside>
				  </section>

				  <section>
				    <h2>¿Cuánto pesa el Elche CF?</h2>
				    <img src='img/pesos-elche.png'
				    alt='pesos de los jugadores del
				    Elche'>

				    <aside class='notes'>Los pesos se
				    han extraído de la página oficial
				    del Elche y no ha sido nada fácil,
				    la transparencia más complicada
				      (después de la del
				    paté). El más delgado es Víctor,
				    un medio, y el más gordo Tyton,
				    uno de los porteros.</aside>
				  </section>

				  <section>
				    <pre><code>my $url = "http://www.elchecf.es/plantilla";
my $dom = Mojo::DOM->new( get $url );
my $jugadores =  $dom->find("div.titulo_datos_comunes");
my @pesos;
for my $p ( @$jugadores ) {
  if ( $p->content() =~ /Peso/ ) {
    my $peso;
    if ( $p->content() =~ /div/ ) {
      ($peso) = ( $p->content() =~ /o: (\d+)/ );
    } else {
      ($peso) = ( $p->content() =~ /(\d+)/ );
    }
    push @pesos, $peso;
  }
}
say("Indice;Peso");
my $i = 1;
say join("\n",map($i++.";".$_, @pesos ));</code></pre>

				    <aside class='notes'>Seguro que la
				    mayoría no entiende nada. Si R es
				    complicado, este lenguaje, llamado
				    Perl, ya es la leche. ¿Alguien lo
				    ha usado? Pues debería, porque
				      hacer esto, <em>rascar</em>
				      información de una página es
				    <em>relativametne</em> (muy
				    relativamente, de hecho),
				    simple. También se puede hacer en
				    R, por cierto, pero no es tan
				    fácil (o si lo es, no tengo ni
				    idea de cómo hacerlo; cada uno usa
				    las herramientas que le resultan
				    más familiares). Perl es software
				    libre y todas las librerías, o
				    colecciones de procedimientos para
				    hacer este tipo de cosas, son
				    también software libre.</aside>
				  </section>

				  <section
				  data-background='https://farm3.staticflickr.com/2811/9825503886_4b9bf98a83_o_d.jpg'
				  title='Numbers'>

				    <aside class='notes'>Hace falta un
				    verdadero detective para extraer
				    los datos. Un detective como
				    Batman... La
				    información qeu hay en una página
				    web está semiestructurada, es
				    decir, tiene una cierta
				    estructura, pero a veces no es
				    totalmente regular o no se puede
				    distinguir a simple vista. Los números
				    están semiocultos, muchas veces
				    simplemente por tener haber hecho
				    la página web a mano, o
				    semiautomáticamente con algún
				    retoque, otras veces por empeño
				    explícito para ocultar datos, como
				    suele suceder en ciertos
				    servicios, empresas o
				    ayuntamientos. La cuestión es que
				    si está en la web y tú lo puedes
				    ver, en la mayoría de las veces,
				      lo puede <em>extraer</em> un
				      programa, así que
				    <em>scraping</em> es siempre una
				    solución de último
				    recurso.</aside>
				  </section>

				<section>
				  <h1>Estoy harto de tanto rascar</h1>
				  <aside class='notes'>Hay
				  herramientas para trabajar con
				  diferentes conjuntos de datos
				  automáticamente e incluso un sitio,
				    <a
				  href='http://morph.io'><code>morph.io</code></a>
				  para almacenar procedimientos de
				  scrapeado y ejecutarlos
				  automáticamente; todo ello en
				  scripts también libres que puedes
				  modificar y adaptar a las
				  necesidades propias. También hay <a
				  href='http://michelleminkoff.com/outwit-needlebase-hands-on-lab/'>extensiones
				      a Firefox como Outwit</a>. Hay
				  que trabajar de <a
				      href='http://en.wikipedia.org/wiki/Web_scraping'>múltiples
				  formas</a> pero, en muchos casos, se
				  pueden obtener datos suficientes
				    como para trabajar. Para hacer
				  scraping en profundidad, en general,
				  hay que tener ciertos conocimientos
				  de programación web y saber, al
				  menos, leer la estructura del fuente
				  de una página web, porque lo que se
				  hace, en la mayor parte de las
				  ocasiones, es eso. En algunos casos
				  también es cuestión de copiar y
				  pegar, pero si tienes que actualizar
				  la información cada cierto tiempo
				  puede acabar siendo muy tedioso. Más
				  recursos, incluyendo <a
				  href='https://zenagiwa.wordpress.com/2014/10/11/non-programmers-guide-to-scraping-data/'>extensiones
				      para Chrome, están en esta
				  página</a>. Incluso si usáis <a
				  href='http://www.labnol.org/internet/google-web-scraping/28450/'>la
				  hoja de cálculo de Google Drive y
				  con un poquito de programación
				  puedes trabajar hasta con cosas que
				      se actualicen periódicamente.</a></aside>
				</section>

				<section
				data-background='https://farm4.staticflickr.com/3129/3206624177_eeea3622ff_b_d.jpg'
				title='los números son chungos'>

				  <aside class='notes'>A veces la
				  forma mejor de ocultar algo es
				  publicarlo. No todo lo publicado es
				  transparente: los PDFs, por ejemplo,
				  son bastante difíciles de consultar:
				  una tabla en PDF es un reto a veces
				  insuperable. Y en algunos casos los
				  PDFs son documentos escaneados,
				  mucho más difíciles todavía de
				  extraer. En resumen: el reto en los
				  datos, en muchas ocasiones y sobre
				  todo en el periodismo de datos, es
				    poder extraerlos.</aside>
				  </aside>
				</section>

				</section>

				<section
				    data-background='https://farm1.staticflickr.com/108/283959170_7885d48f3d_o_d.jpg'
				    title='Números en contenedores'>
				    <aside class='notes'>Vale, ya
				    tenemos todos los numeritos. Pero,
				      ¿qué podemos hacer con los datos
				    si son verdaderamente grandes?</aside>
				</section>

				<section
				data-background='img/paro-elche.png'>
				  <aside class='notes'>Lo primero es
				visualizarlos. Por ejemplo, <a
				href='http://espanaencifras.elespanol.com/?utm_content=bufferee543&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer#home_maps'>estos
				son los datos de variación del paro en
				    Elche y comarca desde 2011</a>,
				    hecho con una herramienta llamada
				<a
				href='http://cartodb.com'>CartoDB</a>,
				software libre hecho por una empresa
				española. Esta aplicación, aparte de
				poder instalártela en tu casa, permite
				subir datos geolocalizados (o
				geolocalizarlos fácilmente) y
				representar de decenas de formas
				diferentes sobre mapas de todo tipo. </aside>
				</section>

				<section>
				  <section data-background='img/presupuestos-cv.png'>
				    <aside class='notes'>En <a
				      href='http://www.dondevanmisimpuestos.es/ccaa/'>Donde
				      Van mis Impuestos</a> visualizan
				      los impuestos de las comunidades
				      autónomas, los globales y los de los
				      ayuntamientos, mostrando dónde van
				      las diferentes partidas y análisis
				      como el presupuesto por
				  persona. Donde van mis impuestos es
				  un proyecto de la <a
				  href='http://www.civio.es/'>Fundación
				      Ciudadana Civio</a>, que tiene
				  otros muchos proyectos relacionados
				  con la transparencia. </aside>
				  </section>

				  <section
				    data-background='img/presupuestos-ugr.png'
				    title='presupuestos de la UGR'>
				    <aside class='notes'>Estos
				  presupuestos fueron extraídos por <a
				  href='http://openkratio.github.io/ugr-presupuestos/'>Félix
				      Ontañón en 2013</a>, además de
				  un PDF, que tiene mucho más
				  mérito. La visualización es todo un
				  arte y contribuye a hacer evidentes
				  relaciones entre cantidades,
				  patrones que se pueden captar a
				  simple vista. Hay empresas como
				  Vizzuality (de donde salió CartoDB)
				      y otra como <a
				  href='http://graphext.com/'>Graphext</a>,
				  creada hace poco por un granadino y
				      afincada en Alicante.</aside>
				  </section>

				</section>
				
				<section data-background='https://farm6.staticflickr.com/5508/11672279656_0660ccd442_k_d.jpg'
				title='la masa'>
				  <aside class='notes'>Una de las
				  opciones es machacar los datos, y si
				  los datos no son muy grandes, o bien
				  ya están preprocesados de alguna
				  forma, podemos hacerlo
				    usando <em>técnicas
				  tradicionales</em>: bases de datos,
				  un sólo ordenador, cosas
				  así. Normalmente, sin embargo,
				    necesitaremos algo un poco más
				potente. Y aquí es donde entra... El
				científico de datos. </aside>
				</section>

				<section>
				  <h2>Esto se parece a...</h2>
				  <img
				  src='img/drowns-vs-nicholas-cage.png'
				  title='Ahogados vs. Pelis de
				  Nicholas Cage'>
				  <aside class='notes'>Hay tantas
				  posibilidades de comparar datos con
				  datos que hasta hay una <a
				  href='http://www.tylervigen.com/spurious-correlations'>página
				    web dedicada a correlaciones
				  espurias</a>. Una vez que se tienen
				  datos, se pueden comparar con
				    cualquier cosa. Se trata de buscar
				  <em>correlaciones</em>, para lo cual
				  hacer gráficos no es suficiente: hay
				  que descartar cualquier otro factor
				  y también usar herramientas
				  estadísticas para probar sin lugar a
				  dudas que existe esa correlación y
				  que un factor depende de
				  otro. <a
				  href='http://stats.stackexchange.com/questions/36/examples-for-teaching-correlation-does-not-mean-causation'>Correlación
				    no implica causación</a>, como lo
				  demuestra el hecho de que el número
				  de premios nóbeles está
				  correlacionado con el consumo de
				  chocolate. </aside>
				</section>

				<section
				data-background='https://farm2.staticflickr.com/1148/1403196887_c7d1e216aa_b_d.jpg'
				title='torrentes de datos'>
				  <aside class='notes'>En realidad,
				nos hemos saltado una parte importante
				    del <em>big data</em>, o lo que lo es
				verdaderamente. Procesamiento de
				grandes cantidades de datos, con las 5
				Vs y la V más importante, la velocidad
				y el volumen, como este torrente
				callejero en Teherán. Es algo que tu
				ordenador solitario no va a poder
				    procesar. En general, necesitarás
				la nube.</aside>
				</section>

				<section
				data-background='https://farm4.staticflickr.com/3507/3887649008_8cf9e7027e_b_d.jpg'
				title='Nubes sobre Trondheim, foto
				mía'>
				  <aside class='notes'>En general,
				hace falta trabajar con la nube. La
				nube, para lo que nos interesa, es una
				infraestructura de computación que es
				escalable y que se paga por
				uso, compuesta por máquinas virtuales
				con algún tipo de software
				ejecutándose (libre, claro) y
				configuradas también por
				software. Hay cloud de unos cuantos
				"players" que incluye a Amazon, Google,
				Microsoft. La nube se adapta a la
				necesidad que cada persona
				tenga. Pero, a este nivel, simplemente
				estamos ejecutando una aplicación (con
				equilibrado o lo que sea) en una
				"máquina" que es elástica (o nubosa,
				que se nos va la
				metáfora). Generalmente hace falta
				    algún tipo de procesamiento
				específico.</aside>

				</section>

				<section>
				  <section
				    data-background='https://farm4.staticflickr.com/3196/3047558085_c2e7e88386_b_d.jpg'
				  title='map reduced'>

				    <aside class='notes'>Posiblemente el
				      peor chiste de la charla: mapa
				      reducido, o <em>map reduce</em>,
				      una de las técnicas principales
				      aplicadas en <em>big data</em>
				para procesar grandes cantidades de
				datos. Consiste en un procesamiento en
				    dos fases</aside>
				  
				  </section>

				  <section>
				  <img
				  src='http://upload.wikimedia.org/wikipedia/commons/9/9a/Mapreduce_%28Ville_Tuulos%29.png' style='height:600px'
				  title='map-reduce'>

				  <aside class='notes'>Los datos son
				    aplicados (que es lo que significa
				    map) es decir, filtrados, o extraídos,
				    ordenados, a una serie de resultados
				    intermedios, que más adelante son
				    agregados (por ejemplo, sumados
				    siguiendo algún criterio) o reducidos
				    de forma que den unos datos que son
				    los que, eventualmente se van a
				    utilizar. Google aplica continuamente
				    este tipo de procesamiento para
				    presentar las tendencias, para dar el
				    número de resultados de una consulta y
				    para cosas similares.</aside>
				  </section>

				  <section>
				    <h2>MapReduce es Hadoop</h2>
				    <img src='http://upload.wikimedia.org/wikipedia/commons/0/0e/Hadoop_logo.svg' title='"Hadoop logo" by
				  Apache Software Foundation -
				  https://svn.apache.org/repos/asf/hadoop/logos/out_rgb/. Licensed
				  under Apache License 2.0 via
				  Wikimedia Commons -
				  http://commons.wikimedia.org/wiki/File:Hadoop_logo.svg#/media/File:Hadoop_logo.svg'>

				    <aside class='notes'><a
				    href='http://en.wikipedia.org/wiki/Apache_Hadoop'>Hadoop
				      es un programa</a> de la
				    fundación Apache (la misma del
				    servidor web) y desarrollado
				    originalmente por Yahoo, escrito
				    en Java y que implementa Map
				    reduce sobre un grupo de
				    ordenadores físicos o máquinas
				    virtuales. Normalmente no tiene
				    que preocuparse uno de montarlo:
				    si usas algún recurso en nube ya
				    viene montado automáticamente y no
				    hay más que usarlo, creando
				    programas. Casi todas las grandes
				    empresas de Internet, desde
				    Facebook a Google, usan este tipo
				    de programa, quizás adaptado. Y en
				      la nube es fácil
				    implementarlo. Últimamente se está
				    empezando también a hablar de otra
				    implementación, Spark, que es
				    mucho más rápida que Hadoop
				    (aunque está basada en él) y que
				      está hecha en otro lenguaje, <a
				    href='http://datascience.stackexchange.com/questions/441/what-are-the-use-cases-for-apache-spark-vs-hadoop'>Scala</a>. En
				    general, este mundo de los datos
				    se mueve a una velocidad que es
				    imposible mantenerse al día. Y
				      luego tienes <a
				    href='https://pig.apache.org/'>Pig</a>,
				    un lenguaje para analizar
				      conjuntos de datos, y <a
				    href='http://stackoverflow.com/questions/3356259/difference-between-pig-and-hive-why-have-both'>Hive</a>
				    en caso de que quieras usar datos
				    estructurados. En resumen: hay
				    muchas herramientas para asistir
				    al científico de datos.</aside>
				  </section>

				</section>

				<section data-background='img/machine-learning.jpg'>
				  <aside class='notes'>Hay que ir un
				  poco más allá buscando patrones,
				  aprendiendo cosas y prediciendo qué
				  va a suceder a continuación. Cuando
				  trabajas con mucho data, tela de
				  data, un viaje de data, los
				  algoritmos que se utilizan para
				  aprendizaje tienen que ir sobre la
				  infraestructura anterior. Por
				  ejemplo, <a
				  href='http://mahout.apache.org/users/basics/algorithms.html'>Mahout
				    funciona sobre Spark</a> y tiene
				  todo tipo de algoritmos de
				  clustering, clasificación y de
				    filtrado colaborativo.</aside>
				</section>
				
				<section
				    data-background='https://farm5.staticflickr.com/4146/4984385396_dd18583007_b_d.jpg'
				    title='historias alrededor del fuego'>
				    <aside class='notes'>Lo importante
				    con los datos es que cuenten una
				    historia. Una predicción, un mapa,
				    una gráfica de correlación, no
				    significa absolutamente
				    nada. ¿Existe alguna causa? ¿Cómo
				    puedes explicar lo que ocurre? Si
				    descubres que la cantidad de
				    crímenes está correlacionada con
				    la venta de helados, ¿por qué
				    puede ser? ¿Cómo puedes transmitir
				    lo que los datos te están
				    contando? 
				    </aside>
				</section>

				<section>
				  <h2>Hay <em>mucho data</em></h2>
				  <h1 class='fragment'>Pongamos
				    nosotros la historia</h1>

				  <aside class='notes'>La
				psicohistoria de Asimov va a estar
				jodida. Pero al menos podremos
				entender un poquito mejor nuestro
				mundo y tomar decisiones más
				    informadas.</aside>
				</section>

				<section style="text-align: left;">
					<h1>¿Alguna pregunta?</h1>
				</section>

				 <section>
				   <section>
				     <h2>Créditos</h2>
				     
				     <ol>
				       <li class='credits'>Imagen del
					 bus modificada de <a
					 href='https://www.flickr.com/photos/mtaphotos/10004448523/'>MTA photos</a></li>
				       <li class='credits'>Imagen de la Fundación del <a href='http://johnnymackintosh.com/2011/08/23/influences-on-johnny-mackintosh-isaac-asimov/'>blog de Johnny Mackintosh</a></li>
				       <li class='credits'>Imagen del mulo de <a href='http://www.jacurutu.com/viewtopic.php?f=21&t=3213'>un foro</a></li>
				       <li class='credits'>Imagen de
					 gente con móviles
					 de <a href='https://www.flickr.com/photos/kk/6863172432/'>Kris
					 Krüg</a></li>
				       <li class='credits'>Imagen de
					 fila de sillas
					 por <a href='https://www.flickr.com/photos/2_funky/4999986578/'>2 funky</a></li>
				       <li class='credits'>Uves
					 de <a href='https://www.flickr.com/photos/ancienthistory/11244652695/'>ancient history</a></li>
				       
				       <li class='credits'>Hulk
					 de <a
					 href='https://www.flickr.com/photos/clement127/11672279656/'>Clement127</a></li>
				       
				       <li class='credits'>Zarpa de oso de
					 <a
					   href='https://www.flickr.com/photos/ucumari/15897351745/'>Valerie</a></li>
				       
				   

				     </ol>
				   </section>
				   <section>  <h2>Créditos II</h2>
				     
				     <ol>

				           <li class='credits'>Números de <a
					 href='https://www.flickr.com/photos/andymag/9825503886/'>Andi
					 Maguire</a></li>

				   <li class='credits'><a
				 href='https://www.flickr.com/photos/stuartpilbrow/3206624177/'>Números
				     de Perdidos por
				 StuartPilbrow</a></li>

				   <li class='credits'><a
				 href='https://www.flickr.com/photos/bocadorada/283959170/'>Tuppers
				     de Boca Dorada</a></li>

				   <li class='credits'><a
				     href='https://www.flickr.com/photos/hamed/1403196887/'>Torrente
				     por Hamed Saber</a></li>
				   
				   <li class='credits'><a
				     href='https://www.flickr.com/photos/george/3047558085/'>Mapa
				     doblado de George Oates</a></li>
				   <li class='credits'><a
				     href='https://www.flickr.com/photos/jkirkhart35/4984385396/'>Fuego
				     de campamento de Jerry Kirkhart</a></li>
				   
				 </section>
			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});

		</script>

	</body>
</html>
